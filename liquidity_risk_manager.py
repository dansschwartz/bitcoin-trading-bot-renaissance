# =====================================================
# RENAISSANCE BITCOIN BOT - STEP 9: ADVANCED RISK MANAGEMENT
# File 3: Liquidity Risk Manager
# =====================================================
# "Institutional-grade liquidity analysis with consciousness enhancement"
# Ensures we can always exit positions, even in stressed markets

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any
from datetime import datetime, timedelta
import logging
from dataclasses import dataclass
from enum import Enum
import asyncio
import warnings
warnings.filterwarnings('ignore')

class LiquidityRiskLevel(Enum):
    """Liquidity risk classification levels"""
    EXCELLENT = "excellent"      # < 0.1% slippage expected
    GOOD = "good"               # 0.1-0.5% slippage
    MODERATE = "moderate"       # 0.5-1.5% slippage  
    POOR = "poor"              # 1.5-5% slippage
    CRITICAL = "critical"       # > 5% slippage or illiquid

class ExitUrgency(Enum):
    """Emergency exit urgency levels"""
    ROUTINE = "routine"         # Normal market exit
    EXPEDITED = "expedited"     # Faster than normal exit
    EMERGENCY = "emergency"     # Immediate exit required
    PANIC = "panic"            # Exit at any cost

@dataclass
class LiquidityMetrics:
    """Comprehensive liquidity assessment"""
    bid_ask_spread: float
    market_depth_score: float
    volume_concentration: float
    order_book_imbalance: float
    recent_volatility: float
    estimated_slippage: float
    liquidity_risk_level: LiquidityRiskLevel
    confidence_score: float
    timestamp: datetime

@dataclass
class EmergencyExitPlan:
    """Emergency exit strategy with multiple scenarios"""
    position_size: float
    recommended_exit_chunks: List[float]
    estimated_exit_time: float
    expected_slippage: float
    urgency_level: ExitUrgency
    alternative_venues: List[str]
    hedging_options: List[Dict]
    worst_case_scenario: Dict

class LiquidityRiskManager:
    """
    ðŸŒŠ LIQUIDITY RISK MANAGER ðŸŒŠ

    Renaissance Technologies-inspired liquidity risk analysis with consciousness enhancement.
    Ensures we can always exit positions gracefully, even during market stress.

    Core Features:
    - Real-time market depth analysis
    - Multi-venue liquidity assessment  
    - Emergency exit protocol optimization
    - Consciousness-enhanced predictions
    - Cross-market arbitrage detection
    """

    def __init__(self, 
                 consciousness_boost: float = 0.0,  # +14.2% Renaissance edge
                 max_position_size: float = 1000000,  # $1M max position
                 emergency_exit_threshold: float = 0.05,  # 5% slippage threshold
                 venue_weights: Optional[Dict[str, float]] = None):

        self.consciousness_boost = consciousness_boost
        self.max_position_size = max_position_size
        self.emergency_exit_threshold = emergency_exit_threshold

        # Venue importance weights for liquidity analysis
        self.venue_weights = venue_weights or {
            'binance': 0.35,     # Largest volume
            'coinbase': 0.25,    # US institutional
            'kraken': 0.15,      # European institutional  
            'ftx': 0.10,         # Derivatives (if available)
            'bitstamp': 0.10,    # European retail
            'gemini': 0.05       # US retail
        }

        # Historical liquidity parameters (consciousness-enhanced)
        consciousness_factor = 1 + self.consciousness_boost
        self.liquidity_params = {
            'depth_multiplier': 2.5 * consciousness_factor,
            'spread_sensitivity': 1.8 * consciousness_factor,
            'volume_decay_rate': 0.85 * consciousness_factor,
            'imbalance_threshold': 0.3 / consciousness_factor,
            'volatility_adjustment': 1.4 * consciousness_factor
        }

        # Setup logging
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)

        # Initialize market data storage
        self.market_data_cache = {}
        self.liquidity_history = []

        print("ðŸŒŠ LIQUIDITY RISK MANAGER INITIALIZED ðŸŒŠ")
        print(f"ðŸ“Š Consciousness Enhancement: +{consciousness_boost*100:.1f}%")
        print(f"ðŸ’° Maximum Position Size: ${max_position_size:,.0f}")
        print(f"ðŸš¨ Emergency Exit Threshold: {emergency_exit_threshold*100:.1f}%")

    def analyze_market_depth(self, 
                           order_book: Dict,
                           recent_trades: List[Dict],
                           current_price: float) -> LiquidityMetrics:
        """
        ðŸ” ENHANCED MARKET DEPTH ANALYSIS

        Analyzes order book depth with consciousness enhancement
        for superior liquidity assessment.
        """
        try:
            # Extract order book data
            bids = np.array([[float(price), float(size)] for price, size in order_book.get('bids', [])])
            asks = np.array([[float(price), float(size)] for price, size in order_book.get('asks', [])])

            if len(bids) == 0 or len(asks) == 0:
                return self._create_emergency_liquidity_metrics()

            # 1. BID-ASK SPREAD ANALYSIS
            best_bid = bids[0][0] if len(bids) > 0 else current_price * 0.995
            best_ask = asks[0][0] if len(asks) > 0 else current_price * 1.005
            bid_ask_spread = (best_ask - best_bid) / current_price

            # 2. MARKET DEPTH SCORE (consciousness-enhanced)
            consciousness_factor = 1 + self.consciousness_boost

            # Calculate depth within 1% of mid price
            mid_price = (best_bid + best_ask) / 2
            depth_range = mid_price * 0.01

            bid_depth = np.sum(bids[(bids[:, 0] >= mid_price - depth_range), 1])
            ask_depth = np.sum(asks[(asks[:, 0] <= mid_price + depth_range), 1])
            total_depth = bid_depth + ask_depth

            # Consciousness-enhanced depth score
            market_depth_score = min(1.0, (total_depth / 100.0) * consciousness_factor)

            # 3. VOLUME CONCENTRATION ANALYSIS
            recent_volumes = [float(trade.get('quantity', 0)) for trade in recent_trades[-100:]]
            if recent_volumes:
                volume_std = np.std(recent_volumes)
                volume_mean = np.mean(recent_volumes)
                volume_concentration = volume_std / (volume_mean + 1e-8)
            else:
                volume_concentration = 1.0

            # 4. ORDER BOOK IMBALANCE
            total_bid_volume = np.sum(bids[:10, 1])  # Top 10 bids
            total_ask_volume = np.sum(asks[:10, 1])  # Top 10 asks
            order_book_imbalance = abs(total_bid_volume - total_ask_volume) / (total_bid_volume + total_ask_volume + 1e-8)

            # 5. RECENT VOLATILITY IMPACT
            recent_prices = [float(trade.get('price', current_price)) for trade in recent_trades[-50:]]
            if len(recent_prices) > 1:
                recent_volatility = np.std(recent_prices) / np.mean(recent_prices)
            else:
                recent_volatility = 0.01

            # 6. ESTIMATED SLIPPAGE (consciousness-enhanced)
            base_slippage = bid_ask_spread * 0.5  # Half-spread as base
            depth_adjustment = max(0.001, 1.0 - market_depth_score)
            volatility_adjustment = recent_volatility * self.liquidity_params['volatility_adjustment']
            imbalance_adjustment = order_book_imbalance * 0.5

            estimated_slippage = (base_slippage + depth_adjustment + volatility_adjustment + imbalance_adjustment) / consciousness_factor

            # 7. LIQUIDITY RISK CLASSIFICATION
            if estimated_slippage < 0.001:
                risk_level = LiquidityRiskLevel.EXCELLENT
            elif estimated_slippage < 0.005:
                risk_level = LiquidityRiskLevel.GOOD
            elif estimated_slippage < 0.015:
                risk_level = LiquidityRiskLevel.MODERATE
            elif estimated_slippage < 0.05:
                risk_level = LiquidityRiskLevel.POOR
            else:
                risk_level = LiquidityRiskLevel.CRITICAL

            # 8. CONFIDENCE SCORE
            data_quality = min(1.0, len(recent_trades) / 100.0)
            depth_quality = min(1.0, (len(bids) + len(asks)) / 100.0)
            confidence_score = (data_quality * depth_quality * consciousness_factor) / (1 + consciousness_factor)

            metrics = LiquidityMetrics(
                bid_ask_spread=bid_ask_spread,
                market_depth_score=market_depth_score,
                volume_concentration=volume_concentration,
                order_book_imbalance=order_book_imbalance,
                recent_volatility=recent_volatility,
                estimated_slippage=estimated_slippage,
                liquidity_risk_level=risk_level,
                confidence_score=confidence_score,
                timestamp=datetime.now()
            )

            # Cache for historical analysis
            self.liquidity_history.append(metrics)
            if len(self.liquidity_history) > 1000:
                self.liquidity_history = self.liquidity_history[-500:]

            return metrics

        except Exception as e:
            self.logger.error(f"Market depth analysis error: {e}")
            return self._create_emergency_liquidity_metrics()

    def create_emergency_exit_plan(self,
                                 position_size: float,
                                 current_liquidity: LiquidityMetrics,
                                 urgency: ExitUrgency = ExitUrgency.ROUTINE) -> EmergencyExitPlan:
        """
        ðŸš¨ EMERGENCY EXIT PLAN GENERATOR

        Creates optimal exit strategy based on position size,
        market liquidity, and urgency level.
        """
        try:
            consciousness_factor = 1 + self.consciousness_boost

            # 1. DETERMINE EXIT CHUNKS BASED ON MARKET DEPTH
            if current_liquidity.market_depth_score > 0.8:
                # High liquidity - can exit in fewer chunks
                chunk_count = max(1, int(abs(position_size) / 50000))  # $50k chunks
            elif current_liquidity.market_depth_score > 0.5:
                # Moderate liquidity - more chunks needed
                chunk_count = max(2, int(abs(position_size) / 25000))  # $25k chunks
            else:
                # Low liquidity - many small chunks
                chunk_count = max(5, int(abs(position_size) / 10000))  # $10k chunks

            # Adjust for urgency
            urgency_multipliers = {
                ExitUrgency.ROUTINE: 1.0,
                ExitUrgency.EXPEDITED: 0.7,  # Fewer, larger chunks
                ExitUrgency.EMERGENCY: 0.5,
                ExitUrgency.PANIC: 0.3
            }

            chunk_count = max(1, int(chunk_count * urgency_multipliers[urgency]))

            # 2. CALCULATE CHUNK SIZES (consciousness-enhanced distribution)
            base_chunk_size = abs(position_size) / chunk_count
            chunk_sizes = []

            for i in range(chunk_count):
                # Slightly varying chunk sizes to avoid detection
                variance = 0.1 * consciousness_factor * np.random.normal(0, 1)
                chunk_size = base_chunk_size * (1 + variance)
                chunk_sizes.append(min(chunk_size, abs(position_size) - sum(chunk_sizes)))

            # Ensure total matches position size
            remaining = abs(position_size) - sum(chunk_sizes)
            if remaining > 0:
                chunk_sizes[-1] += remaining

            if position_size < 0:  # Short position
                chunk_sizes = [-size for size in chunk_sizes]

            # 3. ESTIMATE EXIT TIME
            base_time_per_chunk = {
                ExitUrgency.ROUTINE: 300,    # 5 minutes per chunk
                ExitUrgency.EXPEDITED: 120,  # 2 minutes per chunk
                ExitUrgency.EMERGENCY: 30,   # 30 seconds per chunk
                ExitUrgency.PANIC: 5         # 5 seconds per chunk
            }

            time_per_chunk = base_time_per_chunk[urgency]
            estimated_exit_time = len(chunk_sizes) * time_per_chunk / consciousness_factor

            # 4. EXPECTED SLIPPAGE CALCULATION
            base_slippage = current_liquidity.estimated_slippage

            # Slippage increases with urgency and position size
            size_impact = min(0.02, abs(position_size) / 1000000 * 0.01)  # 1% per $1M
            urgency_impact = {
                ExitUrgency.ROUTINE: 1.0,
                ExitUrgency.EXPEDITED: 1.5,
                ExitUrgency.EMERGENCY: 2.5,
                ExitUrgency.PANIC: 5.0
            }

            expected_slippage = (base_slippage + size_impact) * urgency_impact[urgency] / consciousness_factor

            # 5. ALTERNATIVE VENUES RECOMMENDATION
            alternative_venues = []
            if expected_slippage > 0.01:  # If high slippage expected
                # Recommend spreading across venues
                sorted_venues = sorted(self.venue_weights.items(), 
                                     key=lambda x: x[1], reverse=True)
                alternative_venues = [venue for venue, weight in sorted_venues[:3]]

            # 6. HEDGING OPTIONS
            hedging_options = []
            if abs(position_size) > 100000:  # Large position
                hedging_options.append({
                    'strategy': 'futures_hedge',
                    'size': abs(position_size) * 0.8,
                    'expected_cost': expected_slippage * 0.3
                })

                hedging_options.append({
                    'strategy': 'options_collar',
                    'size': abs(position_size) * 0.5,
                    'expected_cost': expected_slippage * 0.4
                })

            # 7. WORST CASE SCENARIO
            worst_case_slippage = expected_slippage * 3.0
            worst_case_scenario = {
                'slippage': worst_case_slippage,
                'loss_amount': abs(position_size) * worst_case_slippage,
                'exit_time': estimated_exit_time * 2.0,
                'market_impact': 'Severe liquidity crisis'
            }

            plan = EmergencyExitPlan(
                position_size=position_size,
                recommended_exit_chunks=chunk_sizes,
                estimated_exit_time=estimated_exit_time,
                expected_slippage=expected_slippage,
                urgency_level=urgency,
                alternative_venues=alternative_venues,
                hedging_options=hedging_options,
                worst_case_scenario=worst_case_scenario
            )

            return plan

        except Exception as e:
            self.logger.error(f"Emergency exit plan creation error: {e}")
            return self._create_panic_exit_plan(position_size)

    def assess_cross_venue_liquidity(self, 
                                   venue_data: Dict[str, Dict]) -> Dict[str, Any]:
        """
        ðŸŒ CROSS-VENUE LIQUIDITY ANALYSIS

        Analyzes liquidity across multiple exchanges with
        consciousness-enhanced arbitrage detection.
        """
        try:
            consciousness_factor = 1 + self.consciousness_boost
            venue_assessments = {}
            arbitrage_opportunities = []

            # Analyze each venue
            for venue_name, data in venue_data.items():
                if venue_name not in self.venue_weights:
                    continue

                order_book = data.get('order_book', {})
                recent_trades = data.get('recent_trades', [])
                current_price = data.get('current_price', 0)

                if not order_book or not current_price:
                    continue

                # Get liquidity metrics for this venue
                metrics = self.analyze_market_depth(order_book, recent_trades, current_price)

                # Weight by venue importance
                venue_weight = self.venue_weights[venue_name]
                weighted_score = metrics.market_depth_score * venue_weight * consciousness_factor

                venue_assessments[venue_name] = {
                    'liquidity_metrics': metrics,
                    'venue_weight': venue_weight,
                    'weighted_score': weighted_score,
                    'current_price': current_price,
                    'recommended_allocation': min(0.5, weighted_score)  # Max 50% per venue
                }

            # Detect arbitrage opportunities (consciousness-enhanced)
            prices = {venue: data['current_price'] for venue, data in venue_assessments.items()}
            if len(prices) >= 2:
                min_price_venue = min(prices, key=prices.get)
                max_price_venue = max(prices, key=prices.get)

                price_diff = (prices[max_price_venue] - prices[min_price_venue]) / prices[min_price_venue]

                # Consciousness-enhanced arbitrage threshold
                arbitrage_threshold = 0.001 / consciousness_factor  # 0.1% base threshold

                if price_diff > arbitrage_threshold:
                    # Check if both venues have sufficient liquidity
                    min_venue_liquidity = venue_assessments[min_price_venue]['liquidity_metrics'].market_depth_score
                    max_venue_liquidity = venue_assessments[max_price_venue]['liquidity_metrics'].market_depth_score

                    if min_venue_liquidity > 0.5 and max_venue_liquidity > 0.5:
                        arbitrage_opportunities.append({
                            'buy_venue': min_price_venue,
                            'sell_venue': max_price_venue,
                            'price_difference': price_diff,
                            'estimated_profit': price_diff * 0.8,  # Account for fees
                            'confidence': min(min_venue_liquidity, max_venue_liquidity) * consciousness_factor
                        })

            # Overall liquidity assessment
            total_weighted_score = sum(data['weighted_score'] for data in venue_assessments.values())
            average_slippage = np.mean([data['liquidity_metrics'].estimated_slippage 
                                     for data in venue_assessments.values()])

            return {
                'venue_assessments': venue_assessments,
                'overall_liquidity_score': min(1.0, total_weighted_score),
                'average_slippage': average_slippage,
                'best_venue': max(venue_assessments, key=lambda x: venue_assessments[x]['weighted_score']) if venue_assessments else None,
                'arbitrage_opportunities': arbitrage_opportunities,
                'diversification_recommendation': self._calculate_venue_allocation(venue_assessments),
                'consciousness_enhancement': f"+{self.consciousness_boost*100:.1f}%"
            }

        except Exception as e:
            self.logger.error(f"Cross-venue liquidity analysis error: {e}")
            return {'error': str(e), 'fallback_strategy': 'single_venue_trading'}

    def monitor_liquidity_stress(self, 
                               recent_metrics: List[LiquidityMetrics],
                               lookback_minutes: int = 30) -> Dict[str, Any]:
        """
        ðŸ“Š LIQUIDITY STRESS MONITORING

        Monitors for liquidity stress patterns with consciousness-enhanced
        early warning system.
        """
        try:
            if len(recent_metrics) < 5:
                return {'status': 'insufficient_data', 'recommendation': 'continue_monitoring'}

            consciousness_factor = 1 + self.consciousness_boost
            current_time = datetime.now()

            # Filter metrics within lookback period
            cutoff_time = current_time - timedelta(minutes=lookback_minutes)
            relevant_metrics = [m for m in recent_metrics if m.timestamp >= cutoff_time]

            if len(relevant_metrics) < 3:
                return {'status': 'limited_data', 'recommendation': 'increase_monitoring_frequency'}

            # 1. SLIPPAGE TREND ANALYSIS
            slippages = [m.estimated_slippage for m in relevant_metrics]
            slippage_trend = np.polyfit(range(len(slippages)), slippages, 1)[0]  # Linear trend
            current_slippage = slippages[-1]

            # 2. DEPTH DEGRADATION DETECTION
            depth_scores = [m.market_depth_score for m in relevant_metrics]
            depth_trend = np.polyfit(range(len(depth_scores)), depth_scores, 1)[0]
            current_depth = depth_scores[-1]

            # 3. SPREAD EXPANSION ANALYSIS
            spreads = [m.bid_ask_spread for m in relevant_metrics]
            spread_trend = np.polyfit(range(len(spreads)), spreads, 1)[0]
            current_spread = spreads[-1]

            # 4. VOLATILITY SPIKE DETECTION
            volatilities = [m.recent_volatility for m in relevant_metrics]
            volatility_spike = max(volatilities) / (np.mean(volatilities) + 1e-8)

            # 5. CONSCIOUSNESS-ENHANCED STRESS SCORING
            stress_indicators = {
                'slippage_deterioration': max(0, slippage_trend * 1000),  # Scale to reasonable range
                'depth_degradation': max(0, -depth_trend * 10),
                'spread_expansion': max(0, spread_trend * 1000),
                'volatility_spike': max(0, volatility_spike - 1),
                'absolute_slippage': current_slippage * 100,
                'depth_insufficiency': max(0, 0.5 - current_depth) * 2
            }

            # Weight and combine stress indicators
            weights = {
                'slippage_deterioration': 0.25,
                'depth_degradation': 0.20,
                'spread_expansion': 0.15,
                'volatility_spike': 0.15,
                'absolute_slippage': 0.15,
                'depth_insufficiency': 0.10
            }

            stress_score = sum(stress_indicators[key] * weights[key] for key in weights)
            consciousness_adjusted_score = stress_score / consciousness_factor  # Enhanced detection

            # 6. STRESS LEVEL CLASSIFICATION
            if consciousness_adjusted_score < 0.1:
                stress_level = "LOW"
                recommendation = "continue_normal_operations"
                urgency = ExitUrgency.ROUTINE
            elif consciousness_adjusted_score < 0.3:
                stress_level = "MODERATE"
                recommendation = "increase_monitoring_reduce_size"
                urgency = ExitUrgency.ROUTINE
            elif consciousness_adjusted_score < 0.6:
                stress_level = "HIGH"
                recommendation = "prepare_exit_strategies"
                urgency = ExitUrgency.EXPEDITED
            elif consciousness_adjusted_score < 1.0:
                stress_level = "CRITICAL"
                recommendation = "immediate_position_reduction"
                urgency = ExitUrgency.EMERGENCY
            else:
                stress_level = "EXTREME"
                recommendation = "emergency_exit_all_positions"
                urgency = ExitUrgency.PANIC

            # 7. SPECIFIC RECOMMENDATIONS
            specific_actions = []
            if stress_indicators['slippage_deterioration'] > 0.2:
                specific_actions.append("Reduce position sizes immediately")
            if stress_indicators['depth_degradation'] > 0.3:
                specific_actions.append("Diversify across multiple venues")
            if stress_indicators['volatility_spike'] > 2.0:
                specific_actions.append("Implement volatility hedging")
            if current_spread > 0.005:
                specific_actions.append("Avoid market orders, use limit orders only")

            return {
                'stress_level': stress_level,
                'stress_score': consciousness_adjusted_score,
                'raw_stress_score': stress_score,
                'stress_indicators': stress_indicators,
                'current_metrics': {
                    'slippage': current_slippage,
                    'depth_score': current_depth,
                    'spread': current_spread,
                    'volatility': volatilities[-1] if volatilities else 0
                },
                'trends': {
                    'slippage_trend': slippage_trend,
                    'depth_trend': depth_trend,
                    'spread_trend': spread_trend
                },
                'recommendation': recommendation,
                'exit_urgency': urgency,
                'specific_actions': specific_actions,
                'consciousness_enhancement': f"+{self.consciousness_boost*100:.1f}%",
                'monitoring_frequency': 'high' if consciousness_adjusted_score > 0.3 else 'normal'
            }

        except Exception as e:
            self.logger.error(f"Liquidity stress monitoring error: {e}")
            return {
                'status': 'error',
                'error': str(e),
                'recommendation': 'emergency_risk_reduction',
                'exit_urgency': ExitUrgency.EMERGENCY
            }

    def calculate_liquidity_adjusted_position_size(self,
                                                 target_position: float,
                                                 current_liquidity: LiquidityMetrics,
                                                 risk_tolerance: float = 0.02) -> Dict[str, Any]:
        """
        ðŸ“ LIQUIDITY-ADJUSTED POSITION SIZING

        Calculates optimal position size based on current liquidity conditions
        with consciousness-enhanced risk management.
        """
        try:
            consciousness_factor = 1 + self.consciousness_boost

            # 1. BASE LIQUIDITY ADJUSTMENT
            liquidity_multiplier = min(1.0, current_liquidity.market_depth_score * consciousness_factor)

            # 2. SLIPPAGE-BASED POSITION LIMIT
            max_acceptable_slippage = risk_tolerance  # Use risk tolerance as slippage limit
            if current_liquidity.estimated_slippage > max_acceptable_slippage:
                slippage_multiplier = max_acceptable_slippage / current_liquidity.estimated_slippage
            else:
                slippage_multiplier = 1.0

            # 3. SPREAD-BASED ADJUSTMENT
            spread_threshold = 0.002  # 0.2% spread threshold
            if current_liquidity.bid_ask_spread > spread_threshold:
                spread_multiplier = spread_threshold / current_liquidity.bid_ask_spread
            else:
                spread_multiplier = 1.0

            # 4. VOLATILITY ADJUSTMENT
            volatility_threshold = 0.02  # 2% volatility threshold
            if current_liquidity.recent_volatility > volatility_threshold:
                volatility_multiplier = max(0.5, volatility_threshold / current_liquidity.recent_volatility)
            else:
                volatility_multiplier = 1.0

            # 5. CONFIDENCE-BASED ADJUSTMENT
            confidence_multiplier = current_liquidity.confidence_score * consciousness_factor / (1 + consciousness_factor)

            # 6. COMBINE ALL ADJUSTMENTS
            overall_multiplier = min(
                liquidity_multiplier,
                slippage_multiplier,
                spread_multiplier,
                volatility_multiplier,
                confidence_multiplier
            )

            # Apply consciousness enhancement
            final_multiplier = overall_multiplier * consciousness_factor / (1 + consciousness_factor)

            # 7. CALCULATE ADJUSTED POSITION SIZE
            adjusted_position = target_position * final_multiplier

            # 8. APPLY ABSOLUTE LIMITS
            max_position = min(self.max_position_size, abs(target_position))
            adjusted_position = np.sign(adjusted_position) * min(abs(adjusted_position), max_position)

            # 9. RISK ASSESSMENT
            estimated_cost = abs(adjusted_position) * current_liquidity.estimated_slippage
            risk_level = "LOW" if estimated_cost < abs(target_position) * 0.001 else \
                        "MODERATE" if estimated_cost < abs(target_position) * 0.005 else \
                        "HIGH" if estimated_cost < abs(target_position) * 0.02 else "CRITICAL"

            return {
                'original_target_position': target_position,
                'adjusted_position_size': adjusted_position,
                'adjustment_factor': final_multiplier,
                'adjustment_breakdown': {
                    'liquidity_multiplier': liquidity_multiplier,
                    'slippage_multiplier': slippage_multiplier,
                    'spread_multiplier': spread_multiplier,
                    'volatility_multiplier': volatility_multiplier,
                    'confidence_multiplier': confidence_multiplier,
                    'consciousness_factor': consciousness_factor
                },
                'estimated_slippage_cost': estimated_cost,
                'risk_level': risk_level,
                'liquidity_metrics': current_liquidity,
                'recommended_execution': {
                    'chunk_size': min(50000, abs(adjusted_position) / 5),  # Max 5 chunks
                    'execution_time': max(60, abs(adjusted_position) / 10000),  # 1 min per $10k
                    'order_type': 'limit' if current_liquidity.bid_ask_spread > 0.001 else 'market'
                },
                'consciousness_enhancement': f"+{self.consciousness_boost*100:.1f}%"
            }

        except Exception as e:
            self.logger.error(f"Position sizing calculation error: {e}")
            return {
                'error': str(e),
                'fallback_position': target_position * 0.1,  # Conservative fallback
                'recommendation': 'manual_review_required'
            }

    def _create_emergency_liquidity_metrics(self) -> LiquidityMetrics:
        """Create emergency/fallback liquidity metrics when data is unavailable"""
        return LiquidityMetrics(
            bid_ask_spread=0.01,  # Assume 1% spread
            market_depth_score=0.1,  # Very low depth
            volume_concentration=1.0,  # High concentration
            order_book_imbalance=0.5,  # High imbalance
            recent_volatility=0.05,  # High volatility
            estimated_slippage=0.05,  # High slippage
            liquidity_risk_level=LiquidityRiskLevel.CRITICAL,
            confidence_score=0.1,  # Very low confidence
            timestamp=datetime.now()
        )

    def _create_panic_exit_plan(self, position_size: float) -> EmergencyExitPlan:
        """Create emergency exit plan when normal planning fails"""
        return EmergencyExitPlan(
            position_size=position_size,
            recommended_exit_chunks=[position_size],  # Exit all at once
            estimated_exit_time=30,  # 30 seconds
            expected_slippage=0.1,  # 10% slippage assumption
            urgency_level=ExitUrgency.PANIC,
            alternative_venues=list(self.venue_weights.keys())[:3],
            hedging_options=[],
            worst_case_scenario={
                'slippage': 0.2,
                'loss_amount': abs(position_size) * 0.2,
                'exit_time': 60,
                'market_impact': 'Extreme emergency conditions'
            }
        )

    def _calculate_venue_allocation(self, venue_assessments: Dict) -> Dict[str, float]:
        """Calculate optimal venue allocation based on liquidity scores"""
        total_score = sum(data['weighted_score'] for data in venue_assessments.values())

        if total_score == 0:
            return {venue: 1.0/len(venue_assessments) for venue in venue_assessments}

        return {
            venue: min(0.5, data['weighted_score'] / total_score)  # Max 50% per venue
            for venue, data in venue_assessments.items()
        }
